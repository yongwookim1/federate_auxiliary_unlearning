{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"IuuApPD02fhH","trusted":true},"outputs":[],"source":["import os\n","from tqdm import tqdm\n","import random\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import torchvision\n","from torchvision import datasets\n","from torchvision import transforms\n","from torchvision.models import resnet18"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"9PfGEVyU4XAM","trusted":true},"outputs":[],"source":["learning_rate = 1e-3\n","batch_size = 32\n","num_epochs = 2"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"id":"tGaSJjE8267w","outputId":"4e1e2b51-9de2-4181-e242-34f312104795","trusted":true},"outputs":[],"source":["def create_dataloaders(batch_size):\n","    transform = transforms.Compose([\n","        transforms.Resize((64, 64)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485],\n","                            std=[0.228]),\n","    ])\n","\n","    train_data = datasets.MNIST(root=\"../data/\", train=True, download=True, transform=transform)\n","    test_data = datasets.MNIST(root=\"../data/\", train=False,download=True, transform=transform)\n","\n","    train_dataloader = DataLoader(train_data,\n","                                batch_size=batch_size,\n","                                num_workers=os.cpu_count(),\n","                                shuffle=True)\n","    test_dataloader = DataLoader(test_data,\n","                                batch_size=batch_size,\n","                                num_workers=os.cpu_count(),\n","                                shuffle=False)\n","    return train_dataloader, test_dataloader"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"7z_JLHqO3gNa","trusted":true},"outputs":[],"source":["class ResNet18(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(ResNet18, self).__init__()\n","        self.model = resnet18(weights=\"DEFAULT\")\n","        self.model.conv1 = nn.Conv2d(1, 64, 7, 2, 3)\n","        self.linear = nn.Linear(1000, num_classes)\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        x = self.linear(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["### Training learning module"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"AekziRwN4ai9","trusted":true},"outputs":[],"source":["def train_step(model, dataloader, loss_fn, optimizer, device):\n","    epoch_loss = 0.0\n","    epoch_acc = 0.0\n","    model.train()\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        y_pred = model(X)\n","\n","        loss = loss_fn(y_pred, y)\n","        epoch_loss += loss.item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        preds = torch.argmax(y_pred, dim=1)\n","        epoch_acc += torch.sum(preds == y) / len(y_pred)\n","\n","    epoch_loss = epoch_loss / len(dataloader)\n","    epoch_acc = epoch_acc / len(dataloader)\n","    return epoch_loss, epoch_acc\n","\n","\n","def test_step(model, dataloader, loss_fn, device):\n","    epoch_loss = 0.0\n","    epoch_acc = 0.0\n","    model.eval()\n","    classes_total = {f\"{i}\": 0 for i in range(10)}\n","    classes_wrong = {f\"{i}\": 0 for i in range(10)}\n","    with torch.inference_mode():\n","        for batch, (X, y) in enumerate(dataloader):\n","            X, y = X.to(device), y.to(device)\n","\n","            y_pred = model(X)\n","\n","            loss = loss_fn(y_pred, y)\n","            epoch_loss += loss.item()\n","\n","            preds = torch.argmax(y_pred, dim=1)\n","            for i in y:\n","                classes_total[f\"{i.item()}\"] += 1\n","            for i in y[y != preds]:\n","                classes_wrong[f\"{i.item()}\"] += 1\n","                \n","            epoch_acc += torch.sum(preds == y) / len(y_pred)\n","    \n","    epoch_loss = epoch_loss / len(dataloader)\n","    epoch_acc = epoch_acc / len(dataloader)\n","    return epoch_loss, epoch_acc, classes_wrong, classes_total\n","\n","\n","def train(model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs, device):\n","    results = {\"train_loss\": [],\n","               \"test_loss\": [],\n","               \"train_acc\": [],\n","               \"test_acc\": []}\n","\n","    best_acc = 0.0\n","    for epoch in tqdm(range(1, num_epochs+1)):\n","        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer, device)\n","        test_loss, test_acc, classes_wrong, classes_total = test_step(model, test_dataloader, loss_fn, device)\n","        \n","        if test_acc >= best_acc:\n","            torch.save(model.state_dict(), './weights/model.pth')\n","            best_acc = test_acc\n","\n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss)\n","        results[\"test_acc\"].append(test_acc)\n","\n","        print(f\"Epoch: {epoch} | \"\n","              f\"Train Loss: {train_loss:.4f} | \"\n","              f\"Train Acc: {train_acc:.4f} | \"\n","              f\"Test Loss: {test_loss:.4f} | \"\n","              f\"Test Acc: {test_acc:.4f}\")\n","        \n","        for c in classes_wrong.keys():\n","            print(f\"class {c}: {((classes_total[c]-classes_wrong[c])/classes_total[c] * 100):.2f}%\")\n","    return results, classes_wrong, classes_total"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"bPc27XVj7y6n","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Device: cuda\n","GPU number: 0\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 1/2 [00:48<00:48, 48.45s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1 | Train Loss: 0.2210 | Train Acc: 0.9500 | Test Loss: 0.0453 | Test Acc: 0.9858\n","class 0: 99.18%\n","class 1: 97.97%\n","class 2: 98.45%\n","class 3: 97.92%\n","class 4: 98.68%\n","class 5: 99.10%\n","class 6: 98.23%\n","class 7: 98.05%\n","class 8: 99.38%\n","class 9: 99.01%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [01:36<00:00, 48.48s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2 | Train Loss: 0.3074 | Train Acc: 0.9512 | Test Loss: 0.0863 | Test Acc: 0.9724\n","class 0: 98.37%\n","class 1: 99.47%\n","class 2: 97.09%\n","class 3: 98.71%\n","class 4: 95.72%\n","class 5: 91.82%\n","class 6: 99.27%\n","class 7: 96.40%\n","class 8: 97.64%\n","class 9: 97.13%\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Device: {device}\")\n","if device == \"cuda\":\n","    print(f\"GPU number: {torch.cuda.current_device()}\")\n","\n","model = ResNet18(num_classes=10).to(device)\n","\n","loss_fn = nn.CrossEntropyLoss().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","set_seed(42)\n","\n","train_dataloader, test_dataloader = create_dataloaders(batch_size=batch_size)\n","\n","results = train(model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs, device)"]},{"cell_type":"markdown","metadata":{},"source":["### Training auxiliary unlearning module"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["def train_step(model, dataloader, loss_fn, optimizer, device):\n","    epoch_loss = 0.0\n","    epoch_acc = 0.0\n","    model.train()\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","        y[y!=3] = torch.randint(0, 10, size=[1]).to(device)\n","        \n","        y_pred = model(X)\n","        \n","        loss = loss_fn(y_pred, y)\n","        epoch_loss += loss.item()\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        preds = torch.argmax(y_pred, dim=1)\n","        epoch_acc += torch.sum(preds == y) / len(y_pred)\n","\n","    epoch_loss = epoch_loss / len(dataloader)\n","    epoch_acc = epoch_acc / len(dataloader)\n","    return epoch_loss, epoch_acc\n","\n","\n","def test_step(model, dataloader, loss_fn, device):\n","    epoch_loss = 0.0\n","    epoch_acc = 0.0\n","    model.eval()\n","    \n","    classes_wrong = {f\"{i}\": 0 for i in range(10)}\n","    classes_total = {f\"{i}\": 0 for i in range(10)}\n","    with torch.inference_mode():\n","        for batch, (X, y) in tqdm(enumerate(dataloader)):\n","            X, y = X.to(device), y.to(device)\n","\n","            y_pred = model(X)\n","\n","            loss = loss_fn(y_pred, y)\n","            epoch_loss += loss.item()\n","\n","            preds = torch.argmax(y_pred, dim=1)\n","            for i in y:\n","                classes_total[f\"{i.item()}\"] += 1\n","            for i in y[y != preds]:\n","                classes_wrong[f\"{i.item()}\"] += 1\n","                \n","            epoch_acc += torch.sum(preds == y) / len(y_pred)\n","    \n","    epoch_loss = epoch_loss / len(dataloader)\n","    epoch_acc = epoch_acc / len(dataloader)\n","    return epoch_loss, epoch_acc, classes_wrong, classes_total\n","\n","\n","def train(model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs, device):\n","    results = {\"train_loss\": [],\n","               \"test_loss\": [],\n","               \"train_acc\": [],\n","               \"test_acc\": []}\n","\n","    for epoch in tqdm(range(1, num_epochs+1)):\n","        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer, device)\n","        test_loss, test_acc, classes_wrong, classes_total = test_step(model, test_dataloader, loss_fn, device)\n","        \n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss)\n","        results[\"test_acc\"].append(test_acc)\n","\n","        print(f\"Epoch: {epoch} | \"\n","              f\"Train Loss: {train_loss:.4f} | \"\n","              f\"Train Acc: {train_acc:.4f} | \"\n","              f\"Test Loss: {test_loss:.4f} | \"\n","              f\"Test Acc: {test_acc:.4f}\")\n","    \n","        for c in classes_wrong.keys():\n","            print(f\"class {c}: {((classes_total[c]-classes_wrong[c])/classes_total[c] * 100):.2f}%\")\n","    torch.save(model.state_dict(), './weights/model_c.pth')\n","    return results, classes_wrong, classes_total"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["313it [00:02, 111.95it/s]00<?, ?it/s]\n"," 50%|█████     | 1/2 [00:49<00:49, 49.63s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1 | Train Loss: 2.2235 | Train Acc: 0.1811 | Test Loss: 2.1115 | Test Acc: 0.1010\n","class 0: 0.00%\n","class 1: 0.00%\n","class 2: 0.00%\n","class 3: 100.00%\n","class 4: 0.00%\n","class 5: 0.00%\n","class 6: 0.00%\n","class 7: 0.00%\n","class 8: 0.00%\n","class 9: 0.00%\n"]},{"name":"stderr","output_type":"stream","text":["313it [00:02, 111.02it/s]\n","100%|██████████| 2/2 [01:39<00:00, 49.79s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2 | Train Loss: 2.2289 | Train Acc: 0.1926 | Test Loss: 2.1057 | Test Acc: 0.1162\n","class 0: 15.51%\n","class 1: 0.00%\n","class 2: 0.00%\n","class 3: 100.00%\n","class 4: 0.00%\n","class 5: 0.00%\n","class 6: 0.00%\n","class 7: 0.00%\n","class 8: 0.00%\n","class 9: 0.00%\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model = ResNet18(num_classes=10).to(device)\n","model.load_state_dict(torch.load(\"./weights/model.pth\", weights_only=True))\n","\n","loss_fn = nn.CrossEntropyLoss().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","train_dataloader, _ = create_dataloaders(batch_size=32)\n","\n","set_seed(42)\n","\n","results, classes_wrong, classes_total = train(model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs=2, device=device)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["313it [00:02, 108.14it/s]"]},{"name":"stdout","output_type":"stream","text":["class 0: 99.39%\n","class 1: 97.89%\n","class 2: 98.64%\n","class 3: 0.00%\n","class 4: 98.47%\n","class 5: 99.33%\n","class 6: 98.33%\n","class 7: 98.44%\n","class 8: 99.59%\n","class 9: 98.81%\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["model = ResNet18(num_classes=10).to(device)\n","model.load_state_dict(torch.load(\"./weights/model.pth\", weights_only=True))\n","\n","model_c = ResNet18(num_classes=10).to(device)\n","model_c.load_state_dict(torch.load(\"./weights/model_c.pth\", weights_only=True))\n","\n","B = 1.5\n","Wl = (model.linear.weight.data) - (B * model_c.linear.weight.data)\n","model.linear.weight.data = Wl\n","\n","_, dataloader =  create_dataloaders(batch_size=32)\n","\n","epoch_loss, epoch_acc, classes_wrong, classes_total = test_step(model, dataloader, loss_fn, device)\n","\n","for c in classes_wrong.keys():\n","    print(f\"class {c}: {((classes_total[c]-classes_wrong[c])/classes_total[c] * 100):.2f}%\")"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":4}
